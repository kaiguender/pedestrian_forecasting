{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foot Traffic Forecasting Pipeline\n",
    "\n",
    "This notebook forecasts hourly pedestrian counts for multiple streets in W체rzburg using LightGBM and XGBoost models.\n",
    "\n",
    "**Pipeline Overview:**\n",
    "1. **Setup** - Load configuration and modules\n",
    "2. **Load Data** - Read train/test/solution CSVs\n",
    "3. **Feature Engineering** - Create all features from raw data\n",
    "4. **Model Training** - Train models and evaluate on validation set\n",
    "5. **Generate Submission** - Create predictions for test set\n",
    "6. **Optional: Performance Analysis** - Score against solution\n",
    "7. **Optional: Uncertainty Quantification** - Compute prediction intervals\n",
    "8. **Optional: SHAP Analysis** - Feature importance visualization\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "1. Open `config.py` and set `BASE_PATH` to your project root directory\n",
    "2. Run all cells in sections 1-5 to generate predictions\n",
    "3. Optionally run sections 6-8 for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import copy\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Models\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "# Hyperparameter tuning\n",
    "from scipy.stats import uniform, randint\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "# Configuration\n",
    "import config\n",
    "from config import (\n",
    "    DATA_PATH, GENERAL_DATA_PATH, OUTPUT_PATH,\n",
    "    MODELS_TO_USE, TUNE_MODELS, N_SPLITS, N_ITER, N_POINTS_BAYES, N_JOBS, VERBOSE,\n",
    "    RETRAIN_ON_VAL, DESEASONALIZE, TARGETS,\n",
    "    LGB_PARAMS, XGB_PARAMS\n",
    ")\n",
    "\n",
    "# Custom modules\n",
    "from src.features import create_all_features, get_feature_columns\n",
    "from src.modeling import (\n",
    "    get_cv_splits, tune_model_bayes, get_best_model,\n",
    "    train_models_for_target,\n",
    "    compute_seasonal_factors, apply_deseasonalization, reverse_deseasonalization\n",
    ")\n",
    "from src.evaluation import display_target_metrics, display_feature_importance\n",
    "from src.visualization import plot_model_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PATH CONFIGURATION\n",
      "============================================================\n",
      "Data path:    /Users/kaigu/Documents/Universit채t/Doktorand/Projekte/KI-Regio/kaggle_v2/data_foot_traffic\n",
      "General data: /Users/kaigu/Documents/Universit채t/Doktorand/Projekte/KI-Regio/data_general\n",
      "Output path:  /Users/kaigu/Documents/Universit채t/Doktorand/Projekte/KI-Regio/kaggle_v2/data_foot_traffic/submission.csv\n",
      "\n",
      "Checking paths exist...\n",
      "All paths verified!\n",
      "\n",
      "============================================================\n",
      "MODEL CONFIGURATION\n",
      "============================================================\n",
      "Models to use:     ['xgb']\n",
      "Tune models:       False\n",
      "Retrain on val:    False\n",
      "Deseasonalize:     False\n"
     ]
    }
   ],
   "source": [
    "# Verify paths are configured correctly\n",
    "print(\"=\" * 60)\n",
    "print(\"PATH CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Data path:    {DATA_PATH}\")\n",
    "print(f\"General data: {GENERAL_DATA_PATH}\")\n",
    "print(f\"Output path:  {OUTPUT_PATH}\")\n",
    "print()\n",
    "print(\"Checking paths exist...\")\n",
    "assert DATA_PATH.exists(), f\"DATA_PATH does not exist: {DATA_PATH}\"\n",
    "assert GENERAL_DATA_PATH.exists(), f\"GENERAL_DATA_PATH does not exist: {GENERAL_DATA_PATH}\"\n",
    "print(\"All paths verified!\")\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Models to use:     {MODELS_TO_USE}\")\n",
    "print(f\"Tune models:       {TUNE_MODELS}\")\n",
    "print(f\"Retrain on val:    {RETRAIN_ON_VAL}\")\n",
    "print(f\"Deseasonalize:     {DESEASONALIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Train samples: 92,901\n",
      "Test samples:  1,008\n",
      "Public test samples (usable for training): 504\n"
     ]
    }
   ],
   "source": [
    "# Load all datasets\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "train_df = pd.read_csv(DATA_PATH / 'train.csv')\n",
    "test_df = pd.read_csv(DATA_PATH / 'test.csv')\n",
    "solution_df = pd.read_csv(DATA_PATH / 'solution.csv')\n",
    "val_test_actuals = pd.read_csv(DATA_PATH / 'val_test_actuals.csv')\n",
    "\n",
    "# Extract public test data (can be used for training)\n",
    "X_publicTest = test_df[test_df['id'].isin(solution_df[solution_df.Usage == 'Public'].id)]\n",
    "X_publicTest = X_publicTest.merge(solution_df[solution_df.Usage == 'Public'], on='id', how='left')\n",
    "X_publicTest.drop(columns=['Usage'], inplace=True)\n",
    "\n",
    "# Keep a copy of test_df for submission\n",
    "test_df_submission = copy.deepcopy(test_df)\n",
    "\n",
    "print(f\"Train samples: {len(train_df):,}\")\n",
    "print(f\"Test samples:  {len(test_df):,}\")\n",
    "print(f\"Public test samples (usable for training): {len(X_publicTest):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated train samples: 93,405\n",
      "Updated test samples:  504\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: Augment training data with public test labels\n",
    "# This uses the public leaderboard portion of the test set as additional training data\n",
    "\n",
    "train_df = pd.concat([train_df, X_publicTest], ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "# Remove public test IDs from test_df (since they're now in training)\n",
    "test_df = test_df[~test_df['id'].isin(X_publicTest['id'])].reset_index(drop=True)\n",
    "\n",
    "print(f\"Updated train samples: {len(train_df):,}\")\n",
    "print(f\"Updated test samples:  {len(test_df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:232: FutureWarning: 'H' is deprecated and will be removed in a future version. Please use 'h' instead of 'H'.\n",
      "  ts = pd.to_datetime(df[date_col]) + pd.to_timedelta(df[hour_col] - 1, unit=\"H\")\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding weekday\n",
      "Encoding incidents\n",
      "Encoding collection_type\n",
      "\n",
      "Creating test features...\n",
      "Encoding weekday\n",
      "Encoding incidents\n",
      "Encoding collection_type\n",
      "\n",
      "Creating submission test features...\n",
      "Encoding weekday\n",
      "Encoding incidents\n",
      "Encoding collection_type\n",
      "\n",
      "Train shape after features: (93402, 90)\n",
      "Test shape after features: (501, 84)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:232: FutureWarning: 'H' is deprecated and will be removed in a future version. Please use 'h' instead of 'H'.\n",
      "  ts = pd.to_datetime(df[date_col]) + pd.to_timedelta(df[hour_col] - 1, unit=\"H\")\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:232: FutureWarning: 'H' is deprecated and will be removed in a future version. Please use 'h' instead of 'H'.\n",
      "  ts = pd.to_datetime(df[date_col]) + pd.to_timedelta(df[hour_col] - 1, unit=\"H\")\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n",
      "/Users/kaigu/coding/pedestrian_forecasting/src/features.py:293: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  street_data[f\"{col}_mean_lag{w}h\"] = s.rolling(f\"{w}H\", min_periods=min_periods).mean()\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating training features...\")\n",
    "train_df = create_all_features(train_df)\n",
    "\n",
    "print(\"\\nCreating test features...\")\n",
    "test_df = create_all_features(test_df)\n",
    "\n",
    "print(\"\\nCreating submission test features...\")\n",
    "test_df_submission = create_all_features(test_df_submission)\n",
    "\n",
    "print(f\"\\nTrain shape after features: {train_df.shape}\")\n",
    "print(f\"Test shape after features: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train/validation split\n",
    "# The last week of data per street is used for validation\n",
    "\n",
    "cv_splits = get_cv_splits(train_df, n_splits=1, len_split=168)  # 168 hours = 1 week\n",
    "train_idx, val_idx = cv_splits[0]\n",
    "\n",
    "X_train = train_df.loc[train_idx].copy()\n",
    "X_val = train_df.loc[val_idx].copy()\n",
    "\n",
    "# Get feature columns\n",
    "feature_cols = get_feature_columns(X_train)\n",
    "\n",
    "print(f\"\\nTraining samples: {len(X_train):,}\")\n",
    "print(f\"Validation samples: {len(X_val):,}\")\n",
    "print(f\"Number of features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Model Training\n",
    "\n",
    "This section trains models for each target variable and selects the best performer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models with hyperparameters from config\n",
    "models = {\n",
    "    'lgb': lgb.LGBMRegressor(**LGB_PARAMS),\n",
    "    'xgb': xgb.XGBRegressor(**XGB_PARAMS)\n",
    "}\n",
    "\n",
    "# Hyperparameter search spaces (used only if TUNE_MODELS = True)\n",
    "search_spaces = {\n",
    "    'lgb': {\n",
    "        'n_estimators': Integer(100, 1000),\n",
    "        'learning_rate': Real(0.01, 0.3, prior='uniform'),\n",
    "        'max_depth': Integer(4, 11),\n",
    "        'num_leaves': Integer(50, 300),\n",
    "        'subsample': Real(0.4, 1, prior='uniform'),\n",
    "        'colsample_bytree': Real(0.4, 1, prior='uniform'),\n",
    "        'min_child_samples': Integer(1, 50),\n",
    "        'reg_lambda': Real(0.1, 20, prior='uniform'),\n",
    "    },\n",
    "    'xgb': {\n",
    "        'n_estimators': Integer(100, 1000),\n",
    "        'learning_rate': Real(0.01, 0.3, prior='uniform'),\n",
    "        'max_depth': Integer(4, 11),\n",
    "        'subsample': Real(0.4, 1, prior='uniform'),\n",
    "        'colsample_bytree': Real(0.4, 1, prior='uniform'),\n",
    "        'min_child_weight': Integer(1, 50),\n",
    "        'reg_lambda': Real(0.1, 20, prior='uniform'),\n",
    "    }\n",
    "}\n",
    "\n",
    "# Filter to selected models\n",
    "models_selected = {name: model for name, model in models.items() if name in MODELS_TO_USE}\n",
    "print(f\"Training models: {list(models_selected.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "best_models = {}\n",
    "best_models_saved = {}\n",
    "target_models = {}\n",
    "all_val_predictions = {}\n",
    "all_test_predictions = {}\n",
    "all_submission_predictions = {}\n",
    "\n",
    "for target in TARGETS:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing target: {target}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Prepare data (with optional deseasonalization)\n",
    "    if DESEASONALIZE:\n",
    "        seasonal_factors = compute_seasonal_factors(X_train, target)\n",
    "        X_train_target = apply_deseasonalization(X_train, target, seasonal_factors)\n",
    "        X_val_target = apply_deseasonalization(X_val, target, seasonal_factors)\n",
    "        test_df_target = test_df.merge(seasonal_factors, on=['streetname', 'weekday', 'hour'], how='left')\n",
    "        test_df_sub_target = test_df_submission.merge(seasonal_factors, on=['streetname', 'weekday', 'hour'], how='left')\n",
    "    else:\n",
    "        X_train_target = X_train\n",
    "        X_val_target = X_val\n",
    "        test_df_target = test_df\n",
    "        test_df_sub_target = test_df_submission\n",
    "\n",
    "    # Train all models for this target\n",
    "    val_predictions, test_predictions, models_fitted = train_models_for_target(\n",
    "        X_train=X_train_target,\n",
    "        X_val=X_val_target,\n",
    "        test_df=test_df_target,\n",
    "        target=target,\n",
    "        feature_cols=feature_cols,\n",
    "        models_selected=models_selected,\n",
    "        search_spaces=search_spaces,\n",
    "        tune_models=TUNE_MODELS,\n",
    "        retrain_on_val=RETRAIN_ON_VAL,\n",
    "        n_splits=N_SPLITS,\n",
    "        n_iter=N_ITER,\n",
    "        n_points=N_POINTS_BAYES,\n",
    "        n_jobs=N_JOBS,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "\n",
    "    # Reverse deseasonalization if applied\n",
    "    if DESEASONALIZE:\n",
    "        for model_name in val_predictions:\n",
    "            val_predictions[model_name][target] = reverse_deseasonalization(\n",
    "                val_predictions[model_name][target].values,\n",
    "                X_val_target['seasonal_factor'].values\n",
    "            )\n",
    "            val_predictions[model_name][target] = np.clip(val_predictions[model_name][target], a_min=0, a_max=None)\n",
    "\n",
    "            test_predictions[model_name][target] = reverse_deseasonalization(\n",
    "                test_predictions[model_name][target].values,\n",
    "                test_df_target['seasonal_factor'].values\n",
    "            )\n",
    "            test_predictions[model_name][target] = np.clip(test_predictions[model_name][target], a_min=0, a_max=None)\n",
    "\n",
    "    all_val_predictions[target] = val_predictions\n",
    "    all_test_predictions[target] = test_predictions\n",
    "\n",
    "    # Display metrics\n",
    "    print(f\"\\nMetrics for {target}:\")\n",
    "    display_target_metrics(X_val, val_predictions, target)\n",
    "\n",
    "    # Select best model\n",
    "    best_model, best_mse = get_best_model(models_fitted, X_val[target], val_predictions)\n",
    "    best_models[target] = best_model\n",
    "    print(f\"\\nBest model for {target}: {best_model.upper()} (MSE: {best_mse:.2f})\")\n",
    "\n",
    "    # Feature importance\n",
    "    if best_model in ['rf', 'lgb', 'xgb']:\n",
    "        display_feature_importance(models_fitted[best_model], feature_cols, best_model, target)\n",
    "\n",
    "    # Generate submission predictions using best model\n",
    "    submission_preds = models_fitted[best_model].predict(test_df_sub_target[feature_cols])\n",
    "    if DESEASONALIZE:\n",
    "        submission_preds = reverse_deseasonalization(submission_preds, test_df_sub_target['seasonal_factor'].values)\n",
    "    submission_preds = np.clip(submission_preds, a_min=0, a_max=None)\n",
    "    all_submission_predictions[target] = pd.DataFrame({target: submission_preds}, index=test_df_submission.index)\n",
    "\n",
    "    target_models[target] = models_fitted\n",
    "    best_models_saved[target] = copy.deepcopy(models_fitted[best_model])\n",
    "\n",
    "# Save trained models\n",
    "with open(DATA_PATH / 'best_models.pkl', 'wb') as f:\n",
    "    pickle.dump(best_models_saved, f)\n",
    "print(f\"\\nModels saved to {DATA_PATH / 'best_models.pkl'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "submission_df = pd.DataFrame({'id': test_df_submission['id']})\n",
    "\n",
    "for target in TARGETS:\n",
    "    submission_df[target] = all_submission_predictions[target][target].round(1)\n",
    "\n",
    "submission_df.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "print(f\"Submission file saved to: {OUTPUT_PATH}\")\n",
    "print(f\"\\nSubmission shape: {submission_df.shape}\")\n",
    "print(\"\\nSample predictions:\")\n",
    "submission_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also create a formatted version with additional columns for analysis\n",
    "test_df_formatting = pd.read_csv(DATA_PATH / 'test.csv')\n",
    "\n",
    "submission_df_formatted = test_df_formatting.merge(submission_df, on='id', how='left')\n",
    "submission_df_formatted = submission_df_formatted[[\n",
    "    'id', 'streetname', 'city', 'date', 'hour', 'weekday',\n",
    "    'temperature', 'weather_condition', 'incidents', 'collection_type',\n",
    "    'n_pedestrians', 'n_pedestrians_towards', 'n_pedestrians_away'\n",
    "]]\n",
    "\n",
    "submission_df_formatted.to_csv(DATA_PATH / 'pedestrians_val_test_forecasts.csv', index=False)\n",
    "print(f\"Formatted submission saved to: {DATA_PATH / 'pedestrians_val_test_forecasts.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Optional: Performance Analysis\n",
    "\n",
    "Compare predictions against the solution file to evaluate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions and solution\n",
    "sub = pd.read_csv(OUTPUT_PATH)\n",
    "solution = pd.read_csv(DATA_PATH / 'solution.csv')\n",
    "test_data = pd.read_csv(DATA_PATH / 'test.csv')\n",
    "\n",
    "# Add hour column for filtering\n",
    "sub = sub.merge(test_data[['id', 'hour']], on='id', how='left')\n",
    "solution = solution.merge(test_data[['id', 'hour']], on='id', how='left')\n",
    "\n",
    "# Split into public (validation) and private (test) sets\n",
    "solutionVal = solution[solution.Usage == 'Public'].set_index('id').sort_index()\n",
    "solutionTest = solution[solution.Usage == 'Private'].set_index('id').sort_index()\n",
    "\n",
    "subVal = sub[sub.id.isin(solutionVal.index)].set_index('id').sort_index()\n",
    "subTest = sub[sub.id.isin(solutionTest.index)].set_index('id').sort_index()\n",
    "\n",
    "print(f\"Public (Validation) samples: {len(subVal)}\")\n",
    "print(f\"Private (Test) samples: {len(subTest)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE for validation and test sets\n",
    "mseVal = np.mean((solutionVal[TARGETS] - subVal[TARGETS])**2)\n",
    "mseTest = np.mean((solutionTest[TARGETS] - subTest[TARGETS])**2)\n",
    "\n",
    "print(\"Overall MSE (All Hours):\")\n",
    "print(f\"  Validation (Public):  {mseVal.mean():.2f}\")\n",
    "print(f\"  Test (Private):       {mseTest.mean():.2f}\")\n",
    "\n",
    "print(\"\\nMSE per Target:\")\n",
    "for target in TARGETS:\n",
    "    val_mse = np.mean((solutionVal[target] - subVal[target])**2)\n",
    "    test_mse = np.mean((solutionTest[target] - subTest[target])**2)\n",
    "    print(f\"  {target}:\")\n",
    "    print(f\"    Validation: {val_mse:.2f}\")\n",
    "    print(f\"    Test:       {test_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to daytime hours (8-22) for business-relevant metrics\n",
    "day_mask_val = subVal['hour'].between(8, 22)\n",
    "day_mask_test = subTest['hour'].between(8, 22)\n",
    "\n",
    "subVal_day = subVal[day_mask_val]\n",
    "subTest_day = subTest[day_mask_test]\n",
    "solutionVal_day = solutionVal.loc[subVal_day.index]\n",
    "solutionTest_day = solutionTest.loc[subTest_day.index]\n",
    "\n",
    "mseVal_day = np.mean((solutionVal_day[TARGETS] - subVal_day[TARGETS])**2)\n",
    "mseTest_day = np.mean((solutionTest_day[TARGETS] - subTest_day[TARGETS])**2)\n",
    "\n",
    "print(\"MSE (Daytime Hours 8-22 Only):\")\n",
    "print(f\"  Validation: {mseVal_day.mean():.2f}\")\n",
    "print(f\"  Test:       {mseTest_day.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Optional: Uncertainty Quantification\n",
    "\n",
    "Compute prediction intervals using error quantiles from training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.uncertainty import compute_prediction_intervals, check_calibration\n",
    "from src.visualization import plot_prediction_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute prediction intervals for all targets\n",
    "quantiles = [0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.975, 0.99, 0.995]\n",
    "\n",
    "all_pred_results_train = []\n",
    "all_pred_results_val = []\n",
    "all_pred_results_test = []\n",
    "\n",
    "for target in TARGETS:\n",
    "    print(f\"\\nComputing prediction intervals for {target}...\")\n",
    "    model = best_models_saved[target]\n",
    "    \n",
    "    pred_train, pred_val, pred_test = compute_prediction_intervals(\n",
    "        train_df=X_train,\n",
    "        val_df=X_val,\n",
    "        test_df=test_df,\n",
    "        model=model,\n",
    "        feature_cols=feature_cols,\n",
    "        target=target,\n",
    "        quantiles=quantiles\n",
    "    )\n",
    "    \n",
    "    all_pred_results_train.append(pred_train)\n",
    "    all_pred_results_val.append(pred_val)\n",
    "    all_pred_results_test.append(pred_test)\n",
    "\n",
    "pred_results_train = pd.concat(all_pred_results_train, ignore_index=True)\n",
    "pred_results_val = pd.concat(all_pred_results_val, ignore_index=True)\n",
    "pred_results_test = pd.concat(all_pred_results_test, ignore_index=True)\n",
    "\n",
    "print(f\"\\nPrediction intervals computed.\")\n",
    "print(f\"Train results shape: {pred_results_train.shape}\")\n",
    "print(f\"Val results shape:   {pred_results_val.shape}\")\n",
    "print(f\"Test results shape:  {pred_results_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check calibration: empirical coverage vs nominal coverage\n",
    "print(\"Calibration Check (Validation Set):\")\n",
    "print(\"For well-calibrated intervals, empirical coverage should match quantile level.\")\n",
    "print(\"e.g., 95% quantile should have ~95% of actuals below predicted value.\\n\")\n",
    "\n",
    "calibration = check_calibration(pred_results_val)\n",
    "calibration_pivot = calibration.pivot(index='quantile', columns='target', values='empirical_coverage')\n",
    "calibration_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction intervals for a specific street and target\n",
    "# Adjust parameters as needed\n",
    "\n",
    "plot_prediction_intervals(\n",
    "    pred_results_val,\n",
    "    target=\"n_pedestrians_towards\",\n",
    "    street=\"schoenbornstrasse\",\n",
    "    lower_q=0.05,\n",
    "    upper_q=0.95\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for test data (actuals may not be available)\n",
    "plot_prediction_intervals(\n",
    "    pred_results_test,\n",
    "    target=\"n_pedestrians\",\n",
    "    street=\"spiegelstrasse\",\n",
    "    lower_q=0.05,\n",
    "    upper_q=0.95\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Optional: SHAP Analysis\n",
    "\n",
    "Visualize feature importance using SHAP (SHapley Additive exPlanations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Select which target's model to analyze\n",
    "target_to_analyze = 'n_pedestrians'\n",
    "\n",
    "print(f\"Computing SHAP values for {target_to_analyze}...\")\n",
    "print(\"This may take a few minutes.\")\n",
    "\n",
    "# Create SHAP explainer\n",
    "explainer = shap.Explainer(best_models_saved[target_to_analyze])\n",
    "\n",
    "# Compute SHAP values (use a sample for faster computation)\n",
    "sample_size = min(1000, len(test_df))\n",
    "test_sample = test_df[feature_cols].sample(n=sample_size, random_state=42)\n",
    "shap_values = explainer(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary plot showing feature importance\n",
    "shap.summary_plot(shap_values, test_sample, max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of mean absolute SHAP values\n",
    "shap.plots.bar(shap_values, max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview some training data\n",
    "train_df.iloc[:, 0:20][-20:-15]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
